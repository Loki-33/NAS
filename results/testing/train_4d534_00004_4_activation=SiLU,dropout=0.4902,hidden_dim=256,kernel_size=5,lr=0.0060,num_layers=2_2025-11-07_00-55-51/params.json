{
  "activation": "SiLU",
  "dropout": 0.49018026388477154,
  "hidden_dim": 256,
  "kernel_size": 5,
  "lr": 0.00596064958028241,
  "num_layers": 2
}