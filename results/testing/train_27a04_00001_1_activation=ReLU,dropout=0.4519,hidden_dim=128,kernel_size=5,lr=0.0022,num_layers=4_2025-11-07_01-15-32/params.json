{
  "activation": "ReLU",
  "dropout": 0.45188848052681074,
  "hidden_dim": 128,
  "kernel_size": 5,
  "lr": 0.0021897424105081892,
  "num_layers": 4
}