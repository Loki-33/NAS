{
  "activation": "SiLU",
  "dropout": 0.13962049529411003,
  "hidden_dim": 64,
  "kernel_size": 3,
  "lr": 0.00022658129764544473,
  "num_layers": 4
}